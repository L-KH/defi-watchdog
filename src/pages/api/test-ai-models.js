// TEST API for checking if AI models are working\n// Use this to debug AI model issues\n\nexport const config = {\n  maxDuration: 30,\n  api: {\n    responseLimit: false,\n    bodyParser: {\n      sizeLimit: '1mb'\n    }\n  }\n};\n\nexport default async function handler(req, res) {\n  if (req.method !== 'GET') {\n    return res.status(405).json({ error: 'Method not allowed' });\n  }\n\n  const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;\n  \n  if (!OPENROUTER_API_KEY) {\n    return res.status(500).json({ \n      error: 'OpenRouter API key not configured',\n      solution: 'Add OPENROUTER_API_KEY to your .env.local file'\n    });\n  }\n\n  const testModels = [\n    'google/gemma-2-9b-it:free',\n    'mistralai/mistral-7b-instruct:free',\n    'microsoft/phi-3-medium-128k-instruct:free'\n  ];\n\n  const results = [];\n\n  for (const modelId of testModels) {\n    try {\n      console.log(`Testing ${modelId}...`);\n      \n      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENROUTER_API_KEY}`,\n          'HTTP-Referer': process.env.NEXTAUTH_URL || 'http://localhost:3000',\n          'X-Title': 'DeFi Watchdog Test'\n        },\n        body: JSON.stringify({\n          model: modelId,\n          messages: [\n            {\n              role: 'user',\n              content: 'Respond with exactly this JSON: {\"test\": \"success\", \"model\": \"working\"}'\n            }\n          ],\n          max_tokens: 100,\n          temperature: 0\n        })\n      });\n\n      if (response.ok) {\n        const data = await response.json();\n        const content = data.choices?.[0]?.message?.content;\n        \n        results.push({\n          model: modelId,\n          status: 'SUCCESS',\n          response: content,\n          canParse: content ? isValidJSON(content) : false\n        });\n      } else {\n        const errorText = await response.text();\n        results.push({\n          model: modelId,\n          status: 'ERROR',\n          error: `${response.status}: ${errorText}`\n        });\n      }\n    } catch (error) {\n      results.push({\n        model: modelId,\n        status: 'FAILED',\n        error: error.message\n      });\n    }\n  }\n\n  const workingModels = results.filter(r => r.status === 'SUCCESS');\n  const failedModels = results.filter(r => r.status !== 'SUCCESS');\n\n  return res.status(200).json({\n    summary: {\n      total: testModels.length,\n      working: workingModels.length,\n      failed: failedModels.length,\n      apiKey: `${OPENROUTER_API_KEY.substring(0, 10)}...`\n    },\n    workingModels: workingModels.map(m => m.model),\n    failedModels: failedModels.map(m => ({ model: m.model, error: m.error })),\n    detailedResults: results,\n    recommendation: workingModels.length > 0 \n      ? `✅ ${workingModels.length} models are working. You can use AI analysis.`\n      : `❌ No models are working. Check your API key and network connection.`\n  });\n}\n\nfunction isValidJSON(str) {\n  try {\n    JSON.parse(str);\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n